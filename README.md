# voice-and-hand-gesture-music-player
The Music player with Voice control and Hand gesture recognition
Hands-free control through computer vision and machine learning 
voice-control includes Speech Recognition, PyGame Mixer and Threading.

Tools and techniques:

Python: Core programming language for data collection, model training, and inference.
OpenCV: Facilitates image and video processing, capturing webcam frames, real-time inference, and rendering bounding boxes.
MediaPipe: A Google library providing a pre-trained hand-tracking model for hand landmarks, enhancing gesture detection accuracy.
Scikit-Learn: Used for building and training the gesture recognition model with the RandomForestClassifier and for performance evaluation with metrics like accuracy_score.
NumPy: Supports data manipulation, padding sequences, and efficient handling of arrays.
Pickle: Enables saving and loading datasets and trained models through serialization.
Tkinter: for GUI development, allowing users to interact with buttons, voice commands, and gestures.
Speech Recognition: for processing voice commands, enabling a hands-free user experience.


